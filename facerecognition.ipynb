{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW DOES COMPUTER READS IMAGES\n",
    "\n",
    "- Every coloured image is distributed into 3d matrices, each element of which represent the intensity of brightness. \n",
    "- these matrices (coloured) have 3 channels. R G B.\n",
    "- If there's a black and white image has 1 channel\n",
    "- 100x100 means 100 rows and 100 rows and respectively 3 or 1 channel based on colour.\n",
    "\n",
    "\n",
    "IN OPENCV THE IMAGE IS FIRST CONVERTED TO A NUMPY ARRAY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#READING AN IMAGE(COLOURED)\n",
    "\n",
    "#1 for coloured and 0 for black and white\n",
    "\n",
    "img=cv2.imread(\"dog.jpeg\",1)   #coloured\n",
    "#print(img)\n",
    "#type(img)\n",
    "#print(img.shape) #194rows , 259coloumns, 3channels\n",
    "\n",
    "#DISPLAY IMAGE\n",
    "\"\"\"\n",
    "cv2.imshow(\"dog.jpeg\", img)  #OPENS A WINDOW TO DISPLAY IMAGE\n",
    "\n",
    "cv2.waitKey(2000)                #WINDOW WAITS FOR 2000 milliseconds to close\n",
    "\n",
    "cv2.destroyAllWindows()     \n",
    "\"\"\"\n",
    "\n",
    "#if we don't declare destroyAllWindows, the window will stop responding after nemtioned time.\n",
    "\n",
    "#cleans the window on the basis of parameter of waitforkey function\\\n",
    "\n",
    "#RESIZING\n",
    "\n",
    "\"\"\"\n",
    "resized=cv2.resize(img, (600,600))\n",
    "cv2.imshow(\"dog.jpeg\",resized)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#RESIZING SYMETRICALLY\n",
    "\n",
    "#Here we are making the size of the image just DOUBLE\n",
    "\n",
    "resized_img=cv2.resize(img, (int(img.shape[1]*2), int(img.shape[0]*2)))   \n",
    "\n",
    "cv2.imshow(\"dog\",resized_img)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW DOES FACE RECOGNITION WORKS.\n",
    "\n",
    "- Load an image that has face.\n",
    "- Create a cascade classifier that contains the features of the face\n",
    "- Search for the row and column value of the face numpy array ( THE COORDINATES OF THE FACE RECT lANGLE) \n",
    "- Display the image with the rectangular face box.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[ 18 283  63  63]\n",
      " [303  72 100 100]\n",
      " [ 73 169  40  40]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade=cv2.CascadeClassifier(\"C:\\opencv\\sources\\data\\haarcascades\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#read the image\n",
    "photo=cv2.imread(\"1.jpeg\")\n",
    "\n",
    "gray=cv2.cvtColor(photo, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#identifying the coordinates of face \n",
    "\n",
    "faces=face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5)\n",
    "print(type(faces))\n",
    "print(faces)\n",
    "\n",
    "#creating rectangle around for the coordinates.\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    photo= cv2.rectangle(photo, (x,y), (x+w, y+h), (57, 3, 252), 3)\n",
    "    \n",
    "resized = cv2.resize(photo,(int(photo.shape[1]), int(photo.shape[0])))\n",
    "\n",
    "cv2.imshow(\"FACE RECOGNITION\", photo)\n",
    "\n",
    "cv2.waitKey(20000)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPTUIRNG FIRST FRAME OUT OF A VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[[169 162 143]\n",
      "  [169 162 143]\n",
      "  [169 161 138]\n",
      "  ...\n",
      "  [145 148 119]\n",
      "  [146 147 123]\n",
      "  [146 147 123]]\n",
      "\n",
      " [[167 160 141]\n",
      "  [166 159 140]\n",
      "  [169 161 138]\n",
      "  ...\n",
      "  [144 147 118]\n",
      "  [146 147 123]\n",
      "  [145 146 122]]\n",
      "\n",
      " [[171 160 140]\n",
      "  [173 162 142]\n",
      "  [176 165 138]\n",
      "  ...\n",
      "  [144 145 121]\n",
      "  [145 146 124]\n",
      "  [145 146 124]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[186 178 143]\n",
      "  [185 177 142]\n",
      "  [178 172 137]\n",
      "  ...\n",
      "  [165 157 136]\n",
      "  [165 157 136]\n",
      "  [162 154 133]]\n",
      "\n",
      " [[182 175 143]\n",
      "  [183 176 144]\n",
      "  [178 171 139]\n",
      "  ...\n",
      "  [165 157 134]\n",
      "  [166 158 137]\n",
      "  [164 156 135]]\n",
      "\n",
      " [[183 176 144]\n",
      "  [182 175 143]\n",
      "  [176 171 140]\n",
      "  ...\n",
      "  [166 158 135]\n",
      "  [166 158 135]\n",
      "  [164 156 133]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "#to create a Video_capture object\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "#WE'LL ADD A WINDOW THAT'LL SHOW THE VIDEO\n",
    "\n",
    "check, frame=video.read()\n",
    "\n",
    "#check is a bool datatype that will return true if it is able to read the object or the frame being captured.\n",
    "\n",
    "#adding time for the camera to be on\n",
    "\n",
    "print(check)\n",
    "print(frame)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#now we will add the imshow function\n",
    "\n",
    "cv2.imshow(\"capture\",frame)\n",
    "\n",
    "cv2.waitKey(2000)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#releasing the video\n",
    "\n",
    "video.release()\n",
    "\n",
    "# UNTILL HERE IF WE RUN, WE'll SEE THAT WEBCAM LIGHT BLINKS.\n",
    "\n",
    "# NOW WE'LL ADD A TIME DELAY UP THERE.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPTURING THE VIDEO\n",
    "\n",
    "THE LOGIC IS:\n",
    "- in order to capture a video, we will be usig a 'WHILE' loop. While the condition will be such that, untill unless 'CHECK' is true, Python will display frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "a=1\n",
    "\n",
    "while True:\n",
    "    a=a+1\n",
    "    check, frame = video.read()\n",
    "    print(frame)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv2.imshow(\"CAPTURE\",gray)\n",
    "    \n",
    "    key = cv2.waitKey(1)    #new frame after 1 millisecond\n",
    "    \n",
    "    if key == ord('q'):         #press q to close the windows\n",
    "        break\n",
    "        \n",
    "print(a)   #THIS WILL PRINT THE NUMBER OF FRAMES\n",
    "\n",
    "video.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
